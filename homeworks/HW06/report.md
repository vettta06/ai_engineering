## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: 18000 строк, 39 столбцов (id, target и 37 признаков `f01`–`f37`)
- Целевая переменная: `target` 
    - класс 0:    0.737389
    - класс 1:    0.262611
- Признаки:  все признаки — числовые float64 (`f01`–`f37`)

## 2. Protocol

- Разбиение: train/test 80%/20% с `random_state=42` и `stratify=y`
- Подбор: CV на train (сколько фолдов, что оптимизировали)  
    Гиперпараметры подбирались с помощью 5-фолдовой стратифицированной кросс-валидации на train-выборке, с оптимизацией по `roc_auc` — метрике.
- Метрики: 
    - `accuracy` — общая точность,  
    - `f1` — гармоническое среднее(важна при дисбалансе),  
    - `roc_auc` — устойчива к дисбалансу и показывает качество ранжирования объектов по вероятностям.  

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier(`strategy='most_frequent'`) — baseline, всегда предсказывает класс 0.
- LogisticRegression — линейная модель с `StandardScaler` в Pipeline.
- DecisionTreeClassifier — подбор `max_depth` (2–8), `min_samples_leaf` (1–10), `ccp_alpha` (0.0–0.01).
- RandomForestClassifier — подбор `max_depth` (5–None), `min_samples_leaf` (1–10), `max_features` (`sqrt`, `log2`, 0.5).
- HistGradientBoostingClassifier — подбор `learning_rate` (0.05–0.2), `max_depth` (3–7), `min_samples_leaf` (10–50).


Опционально:

- StackingClassifier — базовые модели: дерево, лес, бустинг; метамодель: LogisticRegression.

## 4. Results

- Таблица/список финальных метрик на test по всем моделям
| Модель                   | Accuracy | F1     | ROC-AUC |
|--------------------------|----------|--------|---------|
| DummyClassifier          | 0.7375   | 0.0000 | —       |
| LogisticRegression       | 0.8119   | 0.5607 | 0.7977  |
| DecisionTree             | 0.8289   | 0.6085 | 0.8288  |
| RandomForest             | 0.8742   | 0.7491 | 0.9260  |
| HistGradientBoosting     | 0.8883   | 0.8101 | 0.9321  |
| StackingClassifier       | 0.8703   | 0.7894 | 0.9233  |

- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение
HistGradientBoostingClassifier (ROC-AUC = 0.9321).  
Он показал наилучшее качество по всем метрикам, что говорит о его способности эффективно моделировать нелинейные зависимости в данных.

## 5. Analysis

- Устойчивость: при фиксированном `random_state=42` результаты полностью воспроизводимы. Без фиксации seed метрики могут немного колебаться, особенно у деревьев, но порядок моделей сохранится.
- Ошибки: confusion matrix для лучшей модели + комментарий
    - True Negative: 2563  
    - False Positive: 92  
    - False Negative: 239  
    - True Positive: 706  
  Модель хорошо находит оба класса, но чаще ошибается в сторону пропуска класса 1 (FN > FP), что типично при дисбалансе.
- Интерпретация: permutation importance (top-10/15) + выводы
    1. `f16`: 0.0705 ± 0.0012  
    2. `f01`: 0.0491 ± 0.0011  
    3. `f07`: 0.0452 ± 0.0010  
    4. `f08`: 0.0367 ± 0.0009  
    5. `f13`: 0.0312 ± 0.0008  
  Признаки `f16`, `f01`, `f07` оказывают наибольшее влияние на предсказание, что указывает на их важность в структуре данных.


## 6. Conclusion

3-6 коротких тезисов: что вы поняли про деревья/ансамбли и про честный ML-протокол.


1. Дерево решений легко переобучается без контроля сложности, но с ограничениями (`max_depth`, `min_samples_leaf`) становится полезной моделью.
2. Ансамбли (Random Forest, Boosting)  превосходят одиночные модели за счёт снижения дисперсии или смещения.
3. HistGradientBoosting показал наилучшее качество благодаря эффективной обработке нелинейных зависимостей и встроенной регуляризации.
4. Честный ML-протокол (фиксированный train/test, CV на train, финальная оценка на test один раз) критически важен для объективного сравнения моделей.
5. ROC-AUC и F1 — необходимые метрики при дисбалансе, в то время как accuracy может вводить в заблуждение.
