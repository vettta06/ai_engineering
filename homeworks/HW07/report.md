# HW07 – Report

> Файл: `homeworks/HW07/report.md`  

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите): `S07-hw-dataset-01.csv`, `S07-hw-dataset-02.csv`, `S07-hw-dataset-03.csv`

### 1.1 Dataset A

- Файл: ``S07-hw-dataset-01.csv``
- Размер: (12 000 строк, 9 столбцов)
- Признаки: все 8 признаков (`f01`–`f08`) — числовые (`float64`), категориальных нет.
- Пропуски: отсутствуют (все столбцы имеют 12 000 non-null значений).
- "Подлости" датасета: признаки находятся в разных шкалах, что может исказить результаты без масштабирования. Также присутствуют потенциально шумовые признаки, влияющие на кластеризацию.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8 000 строк, 4 столбца)
- Признаки: `x1`, `x2`, `z_noise` — все числовые (`float64`).
- Пропуски: отсутствуют.
- "Подлости" датасета: содержит нелинейную структуру, выбросы и явный шумовой признак `z_noise` с высоким стандартным отклонением (std≈8.1). 

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15 000 строк, 5 столбцов)
- Признаки: все 4 признака — числовые (`float64`).
- Пропуски: отсутствуют.
- "Подлости" датасета: содержит кластеры разной плотности и фоновый шум. Признаки имеют разные масштабы, что требует обязательного масштабирования.

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: Для всех трёх датасетов применялся единый препроцессинг через `sklearn.pipeline.Pipeline`, содержащий только `StandardScaler`. Это обеспечивало масштабирование числовых признаков до нулевого среднего и единичной дисперсии. 

- Поиск гиперпараметров:
  - какой диапазон/сетка параметров для KMeans (k) и второго метода (eps/min_samples или linkage/k)
    - KMeans: перебор количества кластеров `k` в диапазоне от 2 до 20. Для каждого `k` использовались фиксированные параметры: `random_state=42`, `n_init=10`, `init='k-means++'`.
    - DBSCAN: перебор `eps` в диапазоне [0.1, 0.2, ..., 3.0] и `min_samples` в [5, 10, 15, 20]. Оптимальное значение `eps` предварительно оценивалось с помощью графика k-расстояний (k=10).
  - чем руководствовались при выборе "лучшего"
    - Основным критерием выбора лучшей модели служил silhouette score, так как он учитывает как компактность кластеров, так и их разделённость. Для DBSCAN метрики рассчитывались только на non-noise точках, чтобы избежать искажений из-за шума. В случае равенства silhouette (как в dataset-01) дополнительно учитывалась устойчивость (ARI).

- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (и как считали для DBSCAN при наличии шума)
   - Рассчитывались три внутренние метрики:
    - `silhouette_score` — главная метрика выбора,
    - `davies_bouldin_score` — чем меньше, тем лучше,
    - `calinski_harabasz_score` — чем больше, тем лучше.
    Для DBSCAN при наличии шума метрики вычислялись только на ненулевых кластерах (`labels != -1`), и доля шума явно указывалась.
- Визуализация: PCA(2D) (и t-SNE, если делали – с какими параметрами)
    - Для каждого датасета строилась PCA(2D) проекция с раскраской по полученным кластерам (для лучшей модели). PCA выполнялась с `n_components=2` и `random_state=42` для воспроизводимости. t-SNE не использовался, так как требует дополнительной интерпретации и не является обязательным.

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.
 - На каждом датасете сравнивались два алгоритма: **KMeans** и **DBSCAN**.

Минимум (для каждого датасета):

- KMeans (поиск `k`, фиксировали `random_state`, `n_init`) - - **KMeans**: перебор `k` от 2 до 20. Фиксированные параметры: `random_state=42`, `n_init=10`.

- Один из:
  - DBSCAN (`eps`, `min_samples`, доля шума), или
  - AgglomerativeClustering (`k`, `linkage`) - **DBSCAN**: перебор `eps` в диапазоне [0.1, 0.2, 0.3, 0.4, 0.5, 0.8, 1.0] и `min_samples` в [5, 10, 15, 20]. Лучшие параметры: `eps=0.1`, `min_samples=10`.

Опционально: третий метод / дополнительные варианты параметров.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, `k=2` 
- Метрики (silhouette / DB / CH): Silhouette = 0.5216, DB = 0.6853, CH = 11786.95  
- Если был DBSCAN: DBSCAN показал silhouette (0.5216) при `eps=2.0`, `min_samples=5` и без шума
- Коротко: KMeans был выбран как более стабильный и простой в настройке. Устойчивость KMeans подтверждена высоким ARI=1.0 при многократных запусках.

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN, `eps=0.1`, `min_samples=10`
- Метрики (silhouette / DB / CH): Silhouette (non-noise) = 0.5812, DB = 0.5780, CH = 2758.12 
- Если был DBSCAN: DBSCAN значительно превзошёл KMeans (silhouette 0.58 против 0.31)
- Коротко: DBSCAN эффективно выделил плотные кластеры среди нелинейной структуры и выбросов. Высокая доля шума соответствует описанию датасета.

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN, `eps=0.1`, `min_samples=10`
- Метрики (silhouette / DB / CH): Silhouette (non-noise) = 0.8121, DB = 0.2449, C = 3564.02H
- Если был DBSCAN: 99.59%, DBSCAN продемонстрировал высокое качество (silhouette=0.81), выделив 5 плотных кластеров из фона
- Коротко: DBSCAN продемонстрировал высокое качество, а KMeans дал низкий результат (silhouette=0.32), что объясняется его неспособностью работать с кластерами разной плотности. Поэтому был выбран DBSCAN.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?
    KMeans "ломается" в двух случаях:  
    1. Наличие нелинейной структуры и выбросов (dataset-02): KMeans пытается разделить пространство на выпуклые, сферические кластеры, что приводит к "размазыванию" границ и включению выбросов в кластеры. Это резко снижает silhouette score и делает разбиение неинформативным.  
    2. Кластеры разной плотности (dataset-03): KMeans стремится уравнять размеры и плотность кластеров, поэтому он не может выделить маленькие плотные группы на фоне разреженного облака точек. В результате кластеры смешиваются, и качество падает.

- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
    - DBSCAN не предполагает форму кластеров и строится на локальной плотности, что позволяет находить нелинейные и произвольные формы.  
    - DBSCAN естественным образом выделяет шум, не принуждая каждую точку принадлежать кластеру. Это критично для dataset-02 и dataset-03, где подавляющее большинство точек — фон.  
    - DBSCAN чувствителен к плотности, поэтому отлично справляется с выделением компактных ядер.

- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
    - Наличие шума и разная плотность кластеров — основной драйвер выбора DBSCAN.  
    - Масштабирование признаков — без `StandardScaler` KMeans и DBSCAN дали бы искажённые результаты из-за разных шкал.
    - Пропуски и категориальные признаки не влияли, так как их не было в выбранных датасетах.


### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход)
    - Проверка устойчивости проводилась для KMeans на dataset-01. Было выполнено 5 пар запусков с разными значениями `random_state`. Для каждой пары рассчитывался ARI — метрика схожести двух разбиений.
- Что получилось (в 3-6 строк): Все 5 значений ARI оказались равны 1.0000, что означает полное совпадение кластеризаций. Это говорит о том, что при фиксированном `k` и достаточном `n_init=10` KMeans даёт абсолютно воспроизводимые результаты на хорошо разделённых данных.
- Вывод: устойчиво/неустойчиво и почему вы так считаете: KMeans устойчив в условиях, для которых он предназначен (выпуклые, компактные кластеры).

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - профили признаков (средние/медианы) **или**
  - любая другая логичная интерпретация
- 3-6 строк выводов
    - Интерпретация кластеров выполнялась визуально через PCA(2D)-проекции, так как истинных меток нет, а анализ профилей признаков в 8D/4D затруднителен без дополнительного анализа.  
        - В dataset-01 PCA показала два чётко разделённых облака, что подтверждает корректность KMeans.  
        - В dataset-02 DBSCAN выделил десятки мелких плотных групп, в то время как остальные точки (91.85%) распределены хаотично — это выбросы и фон.  
        - В dataset-03 видны 5 компактных кластеров в центре PCA-графика, окружённых "туманом" шума (99.59%).  
    - Кластеры можно интерпретировать как локальные плотные регионы, а всё остальное — как аномалии или фон, что особенно ценно в задачах обнаружения аномалий. 


## 6. Conclusion

4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.

1. Нет универсального алгоритма кластеризации: KMeans эффективен только при выпуклых, равномерных кластерах, тогда как DBSCAN незаменим при нелинейных структурах, выбросах и разной плотности.  
2. Препроцессинг критичен: масштабирование через `StandardScaler` необходимо для всех метрик, чувствительных к масштабу — без него результаты искажаются даже при корректном выборе модели.  
3. Silhouette score — надёжный ориентир, но не единственный: он должен дополняться анализом структуры данных (шум, плотность) и визуализацией.  
4. DBSCAN требует осторожного подбора `eps`, но вознаграждает высоким качеством на подходящих данных — даже при огромной доле шума.  
5. Внутренние метрики (DB, CH) согласуются с silhouette, но интерпретировать их сложнее; silhouette остаётся наиболее интуитивной и информативной.  
6. Воспроизводимость важна даже в unsupervised-обучении: фиксация `random_state`, `n_init` и использование Pipeline делают эксперимент честным и повторяемым.  
7. Корректный протокол unsupervised-эксперимента включает: явный препроцессинг, систематический подбор гиперпараметров, расчёт нескольких метрик, визуализацию и анализ шума — без этого выводы необоснованы.